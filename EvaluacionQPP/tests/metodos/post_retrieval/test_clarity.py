import unittest
import numpy as np
import os
import shutil
import pyterrier as pt
import pandas as pd
from EvaluacionQPP.metodos.post_retrieval.clarity import Clarity
from EvaluacionQPP.data.dataset_processor import DatasetProcessor
from EvaluacionQPP.indexing.index_builder import IndexBuilder
from EvaluacionQPP.utils.text_processing import preprocess_text
from EvaluacionQPP.retrieval.retrieval import perform_retrieval
from nltk.stem.snowball import SnowballStemmer

class TestClarity(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        """Set up test fixtures that can be reused for all tests"""
        # Initialize PyTerrier if not already started
        if not pt.started():
            pt.init()
            
        # Create dataset processor with IquiqueDataset
        cls.dataset_processor = DatasetProcessor("iquique_dataset")
        cls.index_builder = IndexBuilder(cls.dataset_processor, "iquique_test")
        
        # Create a temporary index path for testing
        script_dir = os.path.dirname(os.path.abspath(__file__))
        cls.test_index_path = os.path.join(script_dir, "..", "..", "..", "indices", "test_index")
        
        # Clean up any existing index
        if os.path.exists(cls.test_index_path):
            shutil.rmtree(cls.test_index_path)
        
        # Ensure the directory exists
        os.makedirs(os.path.dirname(cls.test_index_path), exist_ok=True)
        
        # Build or load index
        cls.index = cls.index_builder.load_or_build_index(cls.test_index_path)
        
        # Create sample queries
        cls.queries_df = pd.DataFrame([
            {"qid": "0", "query": "playa cavancha iquique"},
            {"qid": "1", "query": "zona franca zofri"},
            {"qid": "2", "query": "museo historia iquique"}
        ])
        
        # Perform retrieval to get results
        cls.retrieval_results = perform_retrieval(
            cls.index,
            cls.queries_df,
            cls.dataset_processor.dataset,
            method='BM25'
        )
        
        # Debug print to check column names
        print("\nRetrieval results columns:", cls.retrieval_results.columns.tolist())
        
        # Add text column to retrieval results for Clarity
        # Using 'docno' instead of 'doc_id' as that's the standard PyTerrier column name
        cls.retrieval_results['text'] = cls.retrieval_results['docno'].map(
            lambda x: cls.dataset_processor.dataset.documents.get(x, "")
        )
        
        # Create Clarity instance
        cls.clarity = Clarity(cls.index_builder, cls.retrieval_results, dataset_name="iquique_dataset")
        
        # Store preprocessed queries for testing
        cls.query_terms = {
            qid: preprocess_text(query, dataset_name="iquique_dataset")
            for qid, query in cls.queries_df.set_index('qid')['query'].items()
        }

    @classmethod
    def tearDownClass(cls):
        """Clean up after all tests"""
        if os.path.exists(cls.test_index_path):
            shutil.rmtree(cls.test_index_path)

    def test_compute_term_frequencies(self):
        """Test term frequency computation"""
        print("\nRunning test_compute_term_frequencies...")
        
        # Test with valid documents
        docs = pd.DataFrame({
            'text': ["playa cavancha iquique", "museo regional iquique"]
        })
        term_freqs = self.clarity._compute_term_frequencies(docs)
        
        self.assertIsInstance(term_freqs, dict)
        self.assertGreater(len(term_freqs), 0)
        print(f"✓ Term frequencies computed: {term_freqs}")
        
        # Test with empty documents
        empty_docs = pd.DataFrame({'text': []})
        empty_freqs = self.clarity._compute_term_frequencies(empty_docs)
        self.assertEqual(len(empty_freqs), 0)
        print("✓ Empty documents handled correctly")
        
        # Test with NaN values
        nan_docs = pd.DataFrame({'text': [np.nan, "valid text", None]})
        nan_freqs = self.clarity._compute_term_frequencies(nan_docs)
        self.assertGreater(len(nan_freqs), 0)
        print("✓ NaN values handled correctly")

    def test_get_collection_probabilities(self):
        """Test collection probability computation"""
        print("\nRunning test_get_collection_probabilities...")
        
        # Test with known terms
        original_terms = ['iquique', 'playa', 'museo']
        print("\nOriginal terms:", original_terms)
        
        # Debug stemming
        stemmed_terms = [preprocess_text(term, dataset_name="iquique_dataset")[0] for term in original_terms]
        print("Stemmed terms:", stemmed_terms)
        
        # Get term frequencies from index
        print("\nTerm frequencies from index:")
        for term, stemmed in zip(original_terms, stemmed_terms):
            lex_entry = self.index.getLexicon().getLexiconEntry(stemmed)
            cf = lex_entry.getFrequency() if lex_entry else 0
            print(f"Term: {term} -> Stemmed: {stemmed} -> CF: {cf}")
        
        probs = self.clarity._get_collection_probabilities(stemmed_terms)
        
        self.assertIsInstance(probs, dict)
        self.assertEqual(len(probs), len(stemmed_terms))
        for term, prob in probs.items():
            print(f"Term: {term} -> Probability: {prob}")
            self.assertGreaterEqual(prob, 0)
            self.assertLessEqual(prob, 1)
        print(f"✓ Collection probabilities computed: {probs}")
        
        # Test with unknown terms
        unknown_terms = ['unknown_term']
        unknown_probs = self.clarity._get_collection_probabilities(unknown_terms)
        self.assertEqual(unknown_probs['unknown_term'], 0)
        print("✓ Unknown terms handled correctly")

    def test_calculate_kl_divergence(self):
        """Test KL-divergence calculation"""
        print("\nRunning test_calculate_kl_divergence...")
        
        # Test with simple distributions
        p_w_topk = {'term1': 0.7, 'term2': 0.3}
        p_w_collection = {'term1': 0.5, 'term2': 0.5}
        
        kl_div = self.clarity._calculate_kl_divergence(p_w_topk, p_w_collection)
        self.assertGreater(kl_div, 0)
        print(f"✓ KL-divergence calculated: {kl_div:.4f}")
        
        # Test with identical distributions
        p_same = {'term1': 0.5, 'term2': 0.5}
        kl_same = self.clarity._calculate_kl_divergence(p_same, p_same)
        self.assertAlmostEqual(kl_same, 0, places=6)
        print("✓ KL-divergence for identical distributions is zero")
        
        # Test with zero probabilities
        p_zeros = {'term1': 0.0, 'term2': 1.0}
        kl_zeros = self.clarity._calculate_kl_divergence(p_zeros, p_w_collection)
        self.assertGreaterEqual(kl_zeros, 0)
        print("✓ Zero probabilities handled correctly")

    def test_compute_score(self):
        """Test Clarity score computation"""
        print("\nRunning test_compute_score...")
        
        # Test with valid query
        query_id = "0"
        query_terms = self.query_terms[query_id]
        topk_docs = self.retrieval_results[self.retrieval_results['qid'] == query_id].head(10)
        
        print(f"\nValid query test:")
        print(f"Query terms: {query_terms}")
        print(f"Number of top-k docs: {len(topk_docs)}")
        
        score = self.clarity.compute_score(query_terms, topk_docs)
        self.assertGreaterEqual(score, 0.0)
        print(f"✓ Clarity score for valid query: {score:.4f}")
        
        # Test with empty query
        empty_score = self.clarity.compute_score([], topk_docs)
        self.assertEqual(empty_score, 0.0)
        print("✓ Empty query handled correctly")
        
        # Test with empty documents
        empty_docs = pd.DataFrame(columns=topk_docs.columns)
        empty_docs_score = self.clarity.compute_score(query_terms, empty_docs)
        self.assertEqual(empty_docs_score, 0.0)
        print("✓ Empty documents handled correctly")

    def test_compute_scores_batch(self):
        """Test batch computation of Clarity scores"""
        print("\nRunning test_compute_scores_batch...")
        
        # Test with multiple queries
        scores = self.clarity.compute_scores_batch(self.query_terms, top_k=10)
        
        self.assertEqual(len(scores), len(self.query_terms))
        self.assertTrue(all(isinstance(score, float) for score in scores.values()))
        
        print("Batch scores:")
        for qid, score in scores.items():
            print(f"Query {qid}: {score:.4f}")
        print("✓ Batch computation successful")

    def test_edge_cases(self):
        """Test edge cases and error handling"""
        print("\nRunning test_edge_cases...")
        
        # Test with empty results DataFrame
        empty_df = pd.DataFrame(columns=['qid', 'docid', 'docno', 'rank', 'docScore', 'query', 'text'])
        empty_clarity = Clarity(self.index_builder, empty_df, dataset_name="iquique_dataset")
        scores = empty_clarity.compute_scores_batch({"0": ["test"]}, top_k=10)
        self.assertEqual(scores["0"], 0.0)
        print("✓ Empty results handled correctly")
        
        # Test with missing text column
        bad_results = self.retrieval_results.copy()
        bad_results = bad_results.drop('text', axis=1)
        bad_clarity = Clarity(self.index_builder, bad_results, dataset_name="iquique_dataset")
        scores = bad_clarity.compute_scores_batch({"0": ["test"]}, top_k=10)
        self.assertEqual(scores["0"], 0.0)
        print("✓ Missing text column handled correctly")

    def test_term_cf_presence(self):
        """Test that 'play' has correct collection frequency"""
        print("\nRunning test_term_cf_presence...")
        
        term = 'play'
        cf = self.clarity.index.term_cf.get(term, 0)
        print(f"Term: {term} -> Collection Frequency: {cf}")
        self.assertGreater(cf, 0, f"Collection frequency for term '{term}' should be greater than 0")
        print("✓ 'play' has correct collection frequency")

    def test_stemming_consistency(self):
        """Test stemming consistency between indexing and retrieval"""
        # First, let's verify what the stemmer actually produces
        stemmer = SnowballStemmer('spanish')
        test_words = {
            "historia": stemmer.stem("historia"),
            "iquique": stemmer.stem("iquique"),
            "playa": stemmer.stem("playa"),
            "museo": stemmer.stem("museo"),
            "cavancha": stemmer.stem("cavancha"),
            "regional": stemmer.stem("regional"),
            "cultural": stemmer.stem("cultural")
        }
        
        # Now use these actual stems in our test cases
        test_cases = [
            ("iquique", test_words["iquique"]),
            ("playa", test_words["playa"]),
            ("museo", test_words["museo"]),
            ("historia", test_words["historia"]),
            ("cavancha", test_words["cavancha"]),
            ("regional", test_words["regional"]),
            ("cultural", test_words["cultural"])
        ]
        
        for original, expected in test_cases:
            # Get stemmed version
            stemmed = preprocess_text(original, dataset_name="iquique_dataset")[0]
            
            # Check if term exists in index
            lex_entry = self.index.getLexicon().getLexiconEntry(stemmed)
            cf = lex_entry.getFrequency() if lex_entry else 0
            
            # Check if term exists in index builder's term statistics
            index_cf = self.index_builder.term_cf.get(stemmed, 0)
            
            # Verify stemming is consistent
            self.assertEqual(stemmed, expected, 
                            f"Stemming mismatch for '{original}': got '{stemmed}', expected '{expected}'")
            
            # Add warning for terms with zero frequency
            if cf == 0 and original in ['playa', 'museo', 'historia']:
                print(f"Warning: Term '{original}' (stemmed: '{stemmed}') has zero collection frequency")
                # Also check if the term appears in any documents
                for doc_id, text in self.dataset_processor.dataset.documents.items():
                    if original.lower() in text.lower():
                        print(f"  Found '{original}' in document {doc_id}")

if __name__ == '__main__':
    unittest.main() 